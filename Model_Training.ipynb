{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offer success prediction model\n",
    "\n",
    "Now that I've engineered features and created training data, in this notebook I will define and train a binary classification model. The goal is to train a binary classification model that intends to predict whether an offer extended to a certain client will be completed or not, based on the provided features.\n",
    "\n",
    "This task is broken down into a few discrete steps:\n",
    "\n",
    "* Upload the data to S3.\n",
    "* Define a benchmark model to compare the binary classification model to.\n",
    "* Define a binary classification model.\n",
    "* Train the model and deploy it.\n",
    "* Evaluate the deployed classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker==1.72.0\n",
      "  Downloading sagemaker-1.72.0.tar.gz (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 13.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: boto3>=1.14.12 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.16.37)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.19.4)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (3.14.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.4.1)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (0.1.5)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (3.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (20.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.37 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (1.19.37)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.37->boto3>=1.14.12->sagemaker==1.72.0) (1.25.11)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.37->boto3>=1.14.12->sagemaker==1.72.0) (2.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker==1.72.0) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker==1.72.0) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker==1.72.0) (1.15.0)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker==1.72.0) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (3.14.0)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker==1.72.0) (1.15.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.37 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (1.19.37)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.19.4)\n",
      "Collecting smdebug-rulesconfig==0.1.4\n",
      "  Downloading smdebug_rulesconfig-0.1.4-py2.py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-1.72.0-py2.py3-none-any.whl size=386358 sha256=5d16971961a60d68d155d314014a596f0c27bdc99124a0fc89b0fec577598f75\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c3/58/70/85faf4437568bfaa4c419937569ba1fe54d44c5db42406bbd7\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: smdebug-rulesconfig, sagemaker\n",
      "  Attempting uninstall: smdebug-rulesconfig\n",
      "    Found existing installation: smdebug-rulesconfig 1.0.0\n",
      "    Uninstalling smdebug-rulesconfig-1.0.0:\n",
      "      Successfully uninstalled smdebug-rulesconfig-1.0.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.19.0\n",
      "    Uninstalling sagemaker-2.19.0:\n",
      "      Successfully uninstalled sagemaker-2.19.0\n",
      "Successfully installed sagemaker-1.72.0 smdebug-rulesconfig-0.1.4\n",
      "\u001b[33mWARNING: You are using pip version 20.3; however, version 21.0 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Make sure I use SageMaker 1.x\n",
    "!pip install sagemaker==1.72.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload data to S3\n",
    "\n",
    "In the first notebook, I created a file named training.csv with the features and class labels. This file has been saved locally at the end of that notebook, and it has to be uploaded to S3 so that the data can be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the name of directory created to save the features data\n",
    "data_dir = 'offers_data'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'data-offers'\n",
    "\n",
    "# upload all data to S3\n",
    "#input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13296\n",
      "(13296, 25)\n"
     ]
    }
   ],
   "source": [
    "# split test data into ground truth and features\n",
    "test_data = pd.read_csv(os.path.join(data_dir, 'test.csv'), header=None)\n",
    "\n",
    "# the first column is ground truth\n",
    "y_test = test_data.values[:,0]\n",
    "print(len(y_test))\n",
    "\n",
    "\n",
    "# save the features to a separate CSV for uploading to S3\n",
    "X_test = pd.DataFrame(test_data.values[:,1:])\n",
    "print(X_test.shape)\n",
    "X_test.to_csv(os.path.join(data_dir, 'test_no_labels.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_location = sagemaker_session.upload_data(os.path.join(data_dir, 'test_no_labels.csv'), key_prefix=prefix)\n",
    "val_location = sagemaker_session.upload_data(os.path.join(data_dir, 'validation.csv'), key_prefix=prefix)\n",
    "train_location = sagemaker_session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-137503110434/data-offers/train.csv\n",
      "s3://sagemaker-us-east-1-137503110434/data-offers/validation.csv\n",
      "s3://sagemaker-us-east-1-137503110434/data-offers/test_no_labels.csv\n"
     ]
    }
   ],
   "source": [
    "print(train_location)\n",
    "print(val_location)\n",
    "print(test_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cell\n",
    "\n",
    "Test that your data has been successfully uploaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# confirm that data is in S3 bucket\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    #print(obj.key)  # uncomment to print all the files\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark model\n",
    "\n",
    "To assess whether the implemented binary classifier actually learns something about the Starbucks customers in the database and the offers they are most likely to respond to, I will compare its performance with a benchmark model of a random general (fair coin). For each offer extended to a client, there is a 50/50 chance that the client will react positively to it. The benchmark model will try to predict whether the customer will complete the offer by tossing a fair coin, with a 50% chance to guess correctly (basically, blind guessing).\n",
    "\n",
    "The trained XGBoost model should do better when I compare its performance with the one of the benchmark model, using the same set of metrics of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPredictor:\n",
    "    \n",
    "    def predict(self, n_samples):\n",
    "        \"\"\"\n",
    "        Randomly generates a list of n_samples predictions (binary: 0/1), each with 0.5 probability.\n",
    "        \"\"\"\n",
    "        \n",
    "        y = np.random.uniform(0, 1, n_samples)\n",
    "        pred_benchmark = [1 if x>0.5 else 0 for x in y]\n",
    "        \n",
    "        return pred_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 1, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the benchmark\n",
    "predictor_benchmark = RandomPredictor()\n",
    "preds_random = predictor_benchmark.predict(10)\n",
    "preds_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the XGBoost model\n",
    "\n",
    "I will be making use of the high level SageMaker API to train this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "container = get_image_uri(sagemaker_session.boto_region_name, 'xgboost', repo_version='1.0-1')\n",
    "\n",
    "# construct the estimator object\n",
    "xgb = sagemaker.estimator.Estimator(container, # The image name of the training container\n",
    "                                    role,\n",
    "                                    train_instance_count=1,\n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(sagemaker_session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyperparameters: default values\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic', #for binary classification problem\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=100,\n",
    "                       eval_metric='auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tunning\n",
    "\n",
    "Create the hyperparameter tuner. I wish to find the best values for the following parameters:\n",
    "* max_depth, \n",
    "* eta,\n",
    "* min_child_weight\n",
    "* subsample\n",
    "* gamma\n",
    "* num_round\n",
    "\n",
    "Number of models to construct (max_jobs) is set to 15, and the number of those that can be trained in parallel (max_parallel_jobs) is set at 3.\n",
    "\n",
    "For more info: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = xgb, #base estimator object\n",
    "                                               objective_metric_name = 'validation:auc', #metric used to compare trained models.\n",
    "                                               objective_type = 'Maximize',\n",
    "                                               max_jobs = 15, #total number of models to train\n",
    "                                               max_parallel_jobs = 3, #number of models to train in parallel\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(3, 10),\n",
    "                                                    'eta'      : ContinuousParameter(0.05, 0.5),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                                   'num_round':IntegerParameter(25, 150)\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# to make sure SageMaker knows the data is in CSV format\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_val = sagemaker.s3_input(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-xgboost-210125-1605-002-aa092f4d'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best performing model\n",
    "xgb_hyperparameter_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-25 16:08:51 Starting - Preparing the instances for training\n",
      "2021-01-25 16:08:51 Downloading - Downloading input data\n",
      "2021-01-25 16:08:51 Training - Training image download completed. Training in progress.\n",
      "2021-01-25 16:08:51 Uploading - Uploading generated training model\n",
      "2021-01-25 16:08:51 Completed - Training job completed\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter _tuning_objective_metric value validation:auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[16:08:42] 39973x25 matrix with 999325 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[16:08:42] 13277x25 matrix with 331925 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Setting up HPO optimized metric to be : auc\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 39973 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 13277 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:1.00000#011validation-auc:1.00000\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:1.00000#011validation-auc:1.00000\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:1.00000#011validation-auc:1.00000\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:1.00000#011validation-auc:1.00000\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:1.00000#011validation-auc:1.00000\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:1.00000#011validation-auc:1.00000\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:1.00000#011validation-auc:1.00000\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:1.00000#011validation-auc:1.00000\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:1.00000#011validation-auc:1.00000\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:1.00000#011validation-auc:1.00000\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:1.00000#011validation-auc:1.00000\u001b[0m\n",
      "Training seconds: 72\n",
      "Billable seconds: 72\n"
     ]
    }
   ],
   "source": [
    "# construct estimator from the best performing model\n",
    "xgb_best = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model\n",
    "\n",
    "Now that I have fit the model to the training data,  I will test it using SageMaker's Batch Transform functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Using already existing model: sagemaker-xgboost-210125-1605-002-aa092f4d\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer = xgb_best.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................\u001b[32m2021-01-25T17:06:26.354:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2021-01-25:17:06:23:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-01-25:17:06:23:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-01-25:17:06:23:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[35m[2021-01-25:17:06:23:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-01-25:17:06:23:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-01-25:17:06:23:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021/01/25 17:06:24 [crit] 18#18: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Jan/2021:17:06:24 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/01/25 17:06:24 [crit] 18#18: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Jan/2021:17:06:24 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-01-25 17:06:24 +0000] [17] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2021-01-25 17:06:24 +0000] [17] [INFO] Listening at: unix:/tmp/gunicorn.sock (17)\u001b[0m\n",
      "\u001b[34m[2021-01-25 17:06:24 +0000] [17] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-01-25 17:06:24 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2021-01-25 17:06:24 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2021-01-25 17:06:24 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2021-01-25 17:06:24 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2021-01-25:17:06:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Jan/2021:17:06:26 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Jan/2021:17:06:26 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-01-25:17:06:26:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021/01/25 17:06:24 [crit] 18#18: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Jan/2021:17:06:24 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2021/01/25 17:06:24 [crit] 18#18: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Jan/2021:17:06:24 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-01-25 17:06:24 +0000] [17] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2021-01-25 17:06:24 +0000] [17] [INFO] Listening at: unix:/tmp/gunicorn.sock (17)\u001b[0m\n",
      "\u001b[35m[2021-01-25 17:06:24 +0000] [17] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-01-25 17:06:24 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[35m[2021-01-25 17:06:24 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2021-01-25 17:06:24 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2021-01-25 17:06:24 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[35m[2021-01-25:17:06:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Jan/2021:17:06:26 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Jan/2021:17:06:26 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-01-25:17:06:26:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Jan/2021:17:06:26 +0000] \"POST /invocations HTTP/1.1\" 200 265496 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Jan/2021:17:06:26 +0000] \"POST /invocations HTTP/1.1\" 200 265496 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-137503110434/sagemaker-xgboost-210125-1605-002-aa092-2021-01-25-17-00-44-562/test_no_labels.csv.out to offers_data/test_no_labels.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.read_csv(os.path.join(data_dir, 'test_no_labels.csv.out'), header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 0 0]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# map y_pred to 0 and 1 with threshold 0.5\n",
    "y_pred = np.array([0 if x < 0.5 else 1 for x in Y_pred])\n",
    "\n",
    "# evaluate y_pred against y_test\n",
    "assert len(y_pred) == len(y_test)\n",
    "assert type(y_pred) == type(y_test)\n",
    "\n",
    "print(y_pred[0:10])\n",
    "print(y_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way we can check that the predictor works fairly as expected, before deploying it and evaluating it against the benchmark model, is to plot the obtained predictions against the ground truth and see what we're getting is along the lines of what we would expect (low number of FPs and FNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot y_pred against y_test to see what we're getting makes more or less sense\n",
    "plt.scatter(y_test, y_pred, marker='x')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Using already existing model: sagemaker-xgboost-210125-1605-002-aa092f4d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb_best.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "# We need to tell the endpoint what format the data we are sending is in\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "xgb_predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into smaller chunks\n",
    "\n",
    "def predict_chunks(data, model, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, model.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.squeeze(np.round(predict_chunks(X_test.values, xgb_predictor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "assert len(test_preds) == len(y_test)\n",
    "assert type(test_preds) == type(y_test)\n",
    "\n",
    "print(test_preds[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "\n",
    "This section defines the functions that calculate the metrics used to evaluate the binary classifier on test data and compare its performance to the performance of the benchmark model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to evaluate the endpoint on test data\n",
    "# returns a variety of model metrics\n",
    "def evaluate(test_preds, test_labels, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction result and ground truth.  \n",
    "    Return binary classification metrics.\n",
    "    :param test_preds: Class prediction from the binary classifier\n",
    "    :param test_labels: Class labels for test data: ground truth\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    roc_auc = roc_auc_score(test_labels, test_preds)\n",
    "    \n",
    "    # print metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actuals'], colnames=['predictions']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print(\"{:<11} {:.3f}\".format('ROC AUC Score:', roc_auc))\n",
    "        print()\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, \n",
    "            'Precision': precision, 'Recall': recall, 'Accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions      0    1\n",
      "actuals                \n",
      "0.0          12872    0\n",
      "1.0              0  424\n",
      "\n",
      "Recall:     1.000\n",
      "Precision:  1.000\n",
      "Accuracy:   1.000\n",
      "ROC AUC Score: 1.000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TP': 424,\n",
       " 'FP': 0,\n",
       " 'FN': 0,\n",
       " 'TN': 12872,\n",
       " 'Precision': 1.0,\n",
       " 'Recall': 1.0,\n",
       " 'Accuracy': 1.0}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions    0.0  1.0\n",
      "actuals                \n",
      "0.0          12872    0\n",
      "1.0              0  424\n",
      "\n",
      "Recall:     1.000\n",
      "Precision:  1.000\n",
      "Accuracy:   1.000\n",
      "ROC AUC Score: 1.000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TP': 424,\n",
       " 'FP': 0,\n",
       " 'FN': 0,\n",
       " 'TN': 12872,\n",
       " 'Precision': 1.0,\n",
       " 'Recall': 1.0,\n",
       " 'Accuracy': 1.0}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate against what has been obtained from the deployed endpoint\n",
    "evaluate(test_preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model against the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the endpoint what format the data we are sending is in\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "\n",
    "Y_pred = xgb_predictor.predict(X_test.values).decode('utf-8')\n",
    "# predictions is currently a comma delimited string and so we would like to break it up\n",
    "# as a numpy array.\n",
    "y_pred = np.fromstring(Y_pred, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-4560824360b0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-4560824360b0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    TO DO:\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "TO DO:\n",
    "    Evaluate with the metrics --> as in the notebook on fraud detection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the data\n",
    "!rm $data_dir/*\n",
    "\n",
    "# delete the directory itself\n",
    "!rmdir $data_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
