{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offer success prediction model\n",
    "\n",
    "Now that I've engineered features and created training data, in this notebook I will define and train a binary classification model. The goal is to train a binary classification model that intends to predict whether an offer extended to a certain client will be completed or not, based on the provided features.\n",
    "\n",
    "This task is broken down into a few discrete steps:\n",
    "\n",
    "* Upload the data to S3.\n",
    "* Define a benchmark model to compare the binary classification model to.\n",
    "* Define a binary classification model.\n",
    "* Train the model and deploy it.\n",
    "* Evaluate the deployed classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker==1.72.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.72.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (3.14.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.19.4)\n",
      "Requirement already satisfied: smdebug-rulesconfig==0.1.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (0.1.4)\n",
      "Requirement already satisfied: boto3>=1.14.12 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.16.37)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (0.1.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (20.7)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.4.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.37 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (1.19.37)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.37->boto3>=1.14.12->sagemaker==1.72.0) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.37->boto3>=1.14.12->sagemaker==1.72.0) (1.25.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker==1.72.0) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker==1.72.0) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker==1.72.0) (1.15.0)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker==1.72.0) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (3.14.0)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker==1.72.0) (1.15.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.37 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (1.19.37)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.19.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.3; however, version 21.0 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Make sure I use SageMaker 1.x\n",
    "!pip install sagemaker==1.72.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload data to S3\n",
    "\n",
    "In the first notebook, I created a file named training.csv with the features and class labels. This file has been saved locally at the end of that notebook, and it has to be uploaded to S3 so that the data can be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the name of directory created to save the features data\n",
    "data_dir = 'offers_data'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'data-offers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13311\n",
      "(13311, 23)\n"
     ]
    }
   ],
   "source": [
    "# split test data into ground truth and features\n",
    "test_data = pd.read_csv(os.path.join(data_dir, 'test.csv'), header=None)\n",
    "\n",
    "# the first column is ground truth\n",
    "y_test = test_data.values[:,0]\n",
    "print(len(y_test))\n",
    "\n",
    "# save the features to a separate CSV for uploading to S3\n",
    "X_test = pd.DataFrame(test_data.values[:,1:])\n",
    "print(X_test.shape)\n",
    "X_test.to_csv(os.path.join(data_dir, 'test_no_labels.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.max(X_test.values) <= 1  # check that I am using a scaled version\n",
    "assert np.min(X_test.values) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_location = sagemaker_session.upload_data(os.path.join(data_dir, 'test_no_labels.csv'), key_prefix=prefix)\n",
    "val_location = sagemaker_session.upload_data(os.path.join(data_dir, 'validation.csv'), key_prefix=prefix)\n",
    "train_location = sagemaker_session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-137503110434/data-offers/train.csv\n",
      "s3://sagemaker-us-east-1-137503110434/data-offers/validation.csv\n",
      "s3://sagemaker-us-east-1-137503110434/data-offers/test_no_labels.csv\n"
     ]
    }
   ],
   "source": [
    "print(train_location)\n",
    "print(val_location)\n",
    "print(test_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cell\n",
    "\n",
    "Test that your data has been successfully uploaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# confirm that data is in S3 bucket\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    #print(obj.key)  # uncomment to print all the files\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark model\n",
    "\n",
    "To assess whether the implemented binary classifier actually learns something about the Starbucks customers in the database and the offers they are most likely to respond to, I will compare its performance with a benchmark model of a random general (fair coin). For each offer extended to a client, there is a 50/50 chance that the client will react positively to it. The benchmark model will try to predict whether the customer will complete the offer by tossing a fair coin, with a 50% chance to guess correctly (basically, blind guessing).\n",
    "\n",
    "The trained XGBoost model should do better when I compare its performance with the one of the benchmark model, using the same set of metrics of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPredictor:\n",
    "    \"\"\"\n",
    "    A naive predictor that guesses whether a customer will respond to an offer, with\n",
    "    the probability of responding prob.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, prob):\n",
    "        self.prob = prob\n",
    "    \n",
    "    def predict(self, n_samples):\n",
    "        \"\"\"\n",
    "        Randomly generates a list of n_samples predictions (binary: 0/1), \n",
    "        with p(1) = prob.\n",
    "        \"\"\"\n",
    "        \n",
    "        y = np.random.uniform(0, 1, n_samples)\n",
    "        pred_benchmark = [1 if x<self.prob else 0 for x in y]\n",
    "        \n",
    "        return np.array(pred_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of customer completing an offer - set to something comparable with the real value from the data\n",
    "prob_complete_offer = 0.59 # around 59% of the customers in the dataset responded positively\n",
    "\n",
    "# Test the benchmark\n",
    "predictor_benchmark = RandomPredictor(prob_complete_offer)\n",
    "preds_random = predictor_benchmark.predict(10)\n",
    "preds_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the XGBoost model\n",
    "\n",
    "I will be making use of the high level SageMaker API to train this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "container = get_image_uri(sagemaker_session.boto_region_name, 'xgboost', repo_version='1.0-1')\n",
    "\n",
    "# construct the estimator object\n",
    "xgb = sagemaker.estimator.Estimator(container, # The image name of the training container\n",
    "                                    role,\n",
    "                                    train_instance_count=1,\n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(sagemaker_session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyperparameters: default values\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic', #for binary classification problem\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=100\n",
    "                        #eval_metric='aucpr' #area under the OR curve, other tried: eval_metric='auc'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tunning\n",
    "\n",
    "Create the hyperparameter tuner. I wish to find the best values for the following parameters:\n",
    "* max_depth, \n",
    "* eta,\n",
    "* min_child_weight\n",
    "* subsample\n",
    "* gamma\n",
    "* num_round\n",
    "\n",
    "Number of models to construct (max_jobs) is set to 15, and the number of those that can be trained in parallel (max_parallel_jobs) is set at 3.\n",
    "\n",
    "For more info: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html ; https://towardsdatascience.com/xgboost-in-amazon-sagemaker-28e5e354dbcd\n",
    "\n",
    "More on AUC PR: https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = xgb, #base estimator object\n",
    "                                               objective_metric_name = 'validation:aucpr', #metric used to compare trained models.\n",
    "                                               objective_type = 'Maximize',\n",
    "                                               max_jobs = 15, #total number of models to train\n",
    "                                               max_parallel_jobs = 3, #number of models to train in parallel\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(3, 10),\n",
    "                                                    'eta'      : ContinuousParameter(0.05, 0.5),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                                   'num_round':IntegerParameter(25, 150)\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# to make sure SageMaker knows the data is in CSV format\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_val = sagemaker.s3_input(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-xgboost-210126-2305-012-3da3856a'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best performing model\n",
    "xgb_hyperparameter_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-26 23:20:35 Starting - Preparing the instances for training\n",
      "2021-01-26 23:20:35 Downloading - Downloading input data\n",
      "2021-01-26 23:20:35 Training - Training image download completed. Training in progress.\n",
      "2021-01-26 23:20:35 Uploading - Uploading generated training model\n",
      "2021-01-26 23:20:35 Completed - Training job completed\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter _tuning_objective_metric value validation:aucpr to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:20:14] 39899x23 matrix with 917677 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:20:14] 13291x23 matrix with 305693 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Setting up HPO optimized metric to be : aucpr\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 39899 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 13291 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-aucpr:0.91900#011validation-aucpr:0.92024\u001b[0m\n",
      "\u001b[34m[1]#011train-aucpr:0.92445#011validation-aucpr:0.92494\u001b[0m\n",
      "\u001b[34m[2]#011train-aucpr:0.92693#011validation-aucpr:0.92665\u001b[0m\n",
      "\u001b[34m[3]#011train-aucpr:0.92827#011validation-aucpr:0.92775\u001b[0m\n",
      "\u001b[34m[4]#011train-aucpr:0.93014#011validation-aucpr:0.92945\u001b[0m\n",
      "\u001b[34m[5]#011train-aucpr:0.93136#011validation-aucpr:0.93075\u001b[0m\n",
      "\u001b[34m[6]#011train-aucpr:0.93185#011validation-aucpr:0.93042\u001b[0m\n",
      "\u001b[34m[7]#011train-aucpr:0.93265#011validation-aucpr:0.93121\u001b[0m\n",
      "\u001b[34m[8]#011train-aucpr:0.93273#011validation-aucpr:0.93158\u001b[0m\n",
      "\u001b[34m[9]#011train-aucpr:0.93352#011validation-aucpr:0.93190\u001b[0m\n",
      "\u001b[34m[10]#011train-aucpr:0.93474#011validation-aucpr:0.93348\u001b[0m\n",
      "\u001b[34m[11]#011train-aucpr:0.93547#011validation-aucpr:0.93388\u001b[0m\n",
      "\u001b[34m[12]#011train-aucpr:0.93607#011validation-aucpr:0.93413\u001b[0m\n",
      "\u001b[34m[13]#011train-aucpr:0.93637#011validation-aucpr:0.93383\u001b[0m\n",
      "\u001b[34m[14]#011train-aucpr:0.93711#011validation-aucpr:0.93438\u001b[0m\n",
      "\u001b[34m[15]#011train-aucpr:0.93803#011validation-aucpr:0.93486\u001b[0m\n",
      "\u001b[34m[16]#011train-aucpr:0.93849#011validation-aucpr:0.93502\u001b[0m\n",
      "\u001b[34m[17]#011train-aucpr:0.93907#011validation-aucpr:0.93529\u001b[0m\n",
      "\u001b[34m[18]#011train-aucpr:0.93938#011validation-aucpr:0.93539\u001b[0m\n",
      "\u001b[34m[19]#011train-aucpr:0.93941#011validation-aucpr:0.93563\u001b[0m\n",
      "\u001b[34m[20]#011train-aucpr:0.93961#011validation-aucpr:0.93576\u001b[0m\n",
      "\u001b[34m[21]#011train-aucpr:0.93967#011validation-aucpr:0.93568\u001b[0m\n",
      "\u001b[34m[22]#011train-aucpr:0.94002#011validation-aucpr:0.93578\u001b[0m\n",
      "\u001b[34m[23]#011train-aucpr:0.94008#011validation-aucpr:0.93561\u001b[0m\n",
      "\u001b[34m[24]#011train-aucpr:0.94019#011validation-aucpr:0.93583\u001b[0m\n",
      "\u001b[34m[25]#011train-aucpr:0.94067#011validation-aucpr:0.93617\u001b[0m\n",
      "\u001b[34m[26]#011train-aucpr:0.94090#011validation-aucpr:0.93645\u001b[0m\n",
      "\u001b[34m[27]#011train-aucpr:0.94124#011validation-aucpr:0.93658\u001b[0m\n",
      "\u001b[34m[28]#011train-aucpr:0.94136#011validation-aucpr:0.93662\u001b[0m\n",
      "\u001b[34m[29]#011train-aucpr:0.94166#011validation-aucpr:0.93683\u001b[0m\n",
      "\u001b[34m[30]#011train-aucpr:0.94183#011validation-aucpr:0.93694\u001b[0m\n",
      "\u001b[34m[31]#011train-aucpr:0.94191#011validation-aucpr:0.93702\u001b[0m\n",
      "\u001b[34m[32]#011train-aucpr:0.94209#011validation-aucpr:0.93716\u001b[0m\n",
      "\u001b[34m[33]#011train-aucpr:0.94227#011validation-aucpr:0.93720\u001b[0m\n",
      "\u001b[34m[34]#011train-aucpr:0.94234#011validation-aucpr:0.93716\u001b[0m\n",
      "\u001b[34m[35]#011train-aucpr:0.94237#011validation-aucpr:0.93717\u001b[0m\n",
      "\u001b[34m[36]#011train-aucpr:0.94264#011validation-aucpr:0.93724\u001b[0m\n",
      "\u001b[34m[37]#011train-aucpr:0.94283#011validation-aucpr:0.93742\u001b[0m\n",
      "\u001b[34m[38]#011train-aucpr:0.94289#011validation-aucpr:0.93744\u001b[0m\n",
      "\u001b[34m[39]#011train-aucpr:0.94316#011validation-aucpr:0.93753\u001b[0m\n",
      "\u001b[34m[40]#011train-aucpr:0.94332#011validation-aucpr:0.93760\u001b[0m\n",
      "\u001b[34m[41]#011train-aucpr:0.94343#011validation-aucpr:0.93752\u001b[0m\n",
      "\u001b[34m[42]#011train-aucpr:0.94349#011validation-aucpr:0.93750\u001b[0m\n",
      "\u001b[34m[43]#011train-aucpr:0.94363#011validation-aucpr:0.93749\u001b[0m\n",
      "\u001b[34m[44]#011train-aucpr:0.94379#011validation-aucpr:0.93757\u001b[0m\n",
      "\u001b[34m[45]#011train-aucpr:0.94386#011validation-aucpr:0.93763\u001b[0m\n",
      "\u001b[34m[46]#011train-aucpr:0.94393#011validation-aucpr:0.93766\u001b[0m\n",
      "\u001b[34m[47]#011train-aucpr:0.94413#011validation-aucpr:0.93778\u001b[0m\n",
      "\u001b[34m[48]#011train-aucpr:0.94419#011validation-aucpr:0.93777\u001b[0m\n",
      "\u001b[34m[49]#011train-aucpr:0.94423#011validation-aucpr:0.93780\u001b[0m\n",
      "\u001b[34m[50]#011train-aucpr:0.94426#011validation-aucpr:0.93783\u001b[0m\n",
      "\u001b[34m[51]#011train-aucpr:0.94437#011validation-aucpr:0.93780\u001b[0m\n",
      "\u001b[34m[52]#011train-aucpr:0.94445#011validation-aucpr:0.93779\u001b[0m\n",
      "\u001b[34m[53]#011train-aucpr:0.94445#011validation-aucpr:0.93779\u001b[0m\n",
      "\u001b[34m[54]#011train-aucpr:0.94449#011validation-aucpr:0.93783\u001b[0m\n",
      "\u001b[34m[55]#011train-aucpr:0.94451#011validation-aucpr:0.93784\u001b[0m\n",
      "\u001b[34m[56]#011train-aucpr:0.94454#011validation-aucpr:0.93785\u001b[0m\n",
      "\u001b[34m[57]#011train-aucpr:0.94458#011validation-aucpr:0.93793\u001b[0m\n",
      "\u001b[34m[58]#011train-aucpr:0.94458#011validation-aucpr:0.93793\u001b[0m\n",
      "\u001b[34m[59]#011train-aucpr:0.94466#011validation-aucpr:0.93798\u001b[0m\n",
      "\u001b[34m[60]#011train-aucpr:0.94476#011validation-aucpr:0.93800\u001b[0m\n",
      "\u001b[34m[61]#011train-aucpr:0.94485#011validation-aucpr:0.93800\u001b[0m\n",
      "\u001b[34m[62]#011train-aucpr:0.94489#011validation-aucpr:0.93796\u001b[0m\n",
      "\u001b[34m[63]#011train-aucpr:0.94496#011validation-aucpr:0.93795\u001b[0m\n",
      "\u001b[34m[64]#011train-aucpr:0.94509#011validation-aucpr:0.93798\u001b[0m\n",
      "\u001b[34m[65]#011train-aucpr:0.94515#011validation-aucpr:0.93802\u001b[0m\n",
      "\u001b[34m[66]#011train-aucpr:0.94515#011validation-aucpr:0.93800\u001b[0m\n",
      "\u001b[34m[67]#011train-aucpr:0.94520#011validation-aucpr:0.93796\u001b[0m\n",
      "\u001b[34m[68]#011train-aucpr:0.94526#011validation-aucpr:0.93798\u001b[0m\n",
      "\u001b[34m[69]#011train-aucpr:0.94539#011validation-aucpr:0.93809\u001b[0m\n",
      "\u001b[34m[70]#011train-aucpr:0.94551#011validation-aucpr:0.93805\u001b[0m\n",
      "\u001b[34m[71]#011train-aucpr:0.94556#011validation-aucpr:0.93809\u001b[0m\n",
      "\u001b[34m[72]#011train-aucpr:0.94573#011validation-aucpr:0.93815\u001b[0m\n",
      "\u001b[34m[73]#011train-aucpr:0.94583#011validation-aucpr:0.93808\u001b[0m\n",
      "\u001b[34m[74]#011train-aucpr:0.94583#011validation-aucpr:0.93808\u001b[0m\n",
      "\u001b[34m[75]#011train-aucpr:0.94593#011validation-aucpr:0.93815\u001b[0m\n",
      "\u001b[34m[76]#011train-aucpr:0.94593#011validation-aucpr:0.93815\u001b[0m\n",
      "\u001b[34m[77]#011train-aucpr:0.94605#011validation-aucpr:0.93825\u001b[0m\n",
      "\u001b[34m[78]#011train-aucpr:0.94605#011validation-aucpr:0.93825\u001b[0m\n",
      "\u001b[34m[79]#011train-aucpr:0.94607#011validation-aucpr:0.93827\u001b[0m\n",
      "\u001b[34m[80]#011train-aucpr:0.94608#011validation-aucpr:0.93827\u001b[0m\n",
      "\u001b[34m[81]#011train-aucpr:0.94620#011validation-aucpr:0.93835\u001b[0m\n",
      "\u001b[34m[82]#011train-aucpr:0.94620#011validation-aucpr:0.93833\u001b[0m\n",
      "\u001b[34m[83]#011train-aucpr:0.94620#011validation-aucpr:0.93833\u001b[0m\n",
      "Training seconds: 78\n",
      "Billable seconds: 78\n"
     ]
    }
   ],
   "source": [
    "# construct estimator from the best performing model\n",
    "xgb_best = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model\n",
    "\n",
    "Now that I have fit the model to the training data,  I will test it using SageMaker's Batch Transform functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer = xgb_best.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................\n",
      ".\u001b[32m2021-01-26T23:31:20.555:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2021-01-26:23:31:18:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-01-26:23:31:18:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-01-26:23:31:18:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[35m[2021-01-26:23:31:18:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-01-26:23:31:18:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-01-26:23:31:18:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021/01/26 23:31:18 [crit] 19#19: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [26/Jan/2021:23:31:18 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/01/26 23:31:18 [crit] 19#19: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [26/Jan/2021:23:31:18 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-01-26 23:31:18 +0000] [17] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2021-01-26 23:31:18 +0000] [17] [INFO] Listening at: unix:/tmp/gunicorn.sock (17)\u001b[0m\n",
      "\u001b[34m[2021-01-26 23:31:18 +0000] [17] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-01-26 23:31:18 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2021-01-26 23:31:18 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2021-01-26 23:31:18 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2021-01-26 23:31:18 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2021-01-26:23:31:20:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [26/Jan/2021:23:31:20 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [26/Jan/2021:23:31:20 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-01-26:23:31:20:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-01-26:23:31:20:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [26/Jan/2021:23:31:21 +0000] \"POST /invocations HTTP/1.1\" 200 255186 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021/01/26 23:31:18 [crit] 19#19: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [26/Jan/2021:23:31:18 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2021/01/26 23:31:18 [crit] 19#19: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [26/Jan/2021:23:31:18 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-01-26 23:31:18 +0000] [17] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2021-01-26 23:31:18 +0000] [17] [INFO] Listening at: unix:/tmp/gunicorn.sock (17)\u001b[0m\n",
      "\u001b[35m[2021-01-26 23:31:18 +0000] [17] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-01-26 23:31:18 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[35m[2021-01-26 23:31:18 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2021-01-26 23:31:18 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2021-01-26 23:31:18 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[35m[2021-01-26:23:31:20:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [26/Jan/2021:23:31:20 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [26/Jan/2021:23:31:20 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-01-26:23:31:20:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-01-26:23:31:20:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [26/Jan/2021:23:31:21 +0000] \"POST /invocations HTTP/1.1\" 200 255186 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-137503110434/sagemaker-xgboost-210126-2305-012-3da38-2021-01-26-23-25-49-738/test_no_labels.csv.out to offers_data/test_no_labels.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.read_csv(os.path.join(data_dir, 'test_no_labels.csv.out'), header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 0 1 1]\n",
      "[0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# map y_pred to 0 and 1 with threshold 0.5\n",
    "y_pred = np.array([0 if x < 0.5 else 1 for x in Y_pred])\n",
    "\n",
    "# evaluate y_pred against y_test\n",
    "assert len(y_pred) == len(y_test)\n",
    "assert type(y_pred) == type(y_test)\n",
    "\n",
    "print(y_pred[0:10])\n",
    "print(y_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way we can check that the predictor works fairly as expected, before deploying it and evaluating it against the benchmark model, is to plot the obtained predictions against the ground truth and see what we're getting is along the lines of what we would expect (low number of FPs and FNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQmklEQVR4nO3dXYxcd3nH8e+DLQPNhoAwrFBs2KCaCiupFDJKgpDKrpJWTpDsG4NsiUCkBCtQtxehVV1RRSj0glKlSKhuy1ZFvEiwGC5gFdymKmQVinDqWIE4dmS0mABLKOElWNrwEiyeXsyYTsazM8e7Z2Z2/vv9SKudc85/zzzPzOxvzvznLTITSdL4e8GoC5Ak1cNAl6RCGOiSVAgDXZIKYaBLUiE2j+qMt27dmlNTU2vez7PPPstll1229oLGhP2WayP1Cva7WidOnPhJZr6i27aRBfrU1BSPPPLImvezsLDA9PT02gsaE/Zbro3UK9jvakXEd1fa5pSLJBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFGNtAnzr0pZ7LkrQeDDOr+gZ6RHwsIp6OiMdX2B4R8ZGIWIyIxyLiDfWX+XwXLpCVfkvSejDsrKpyhP5xYFeP7bcAO1o/B4B/XntZK+u8IE7+4FzP7ZI0CqPIqr6BnpkPAT/rMWQP8MlsOga8NCJeVVeBnZ784FvWtF2ShmEUWRVVvoIuIqaA+zPz6i7b7gc+mJn/3Vr+MvBXmXnRB7VExAGaR/FMTk5eNzc3t+rCL9zbTb4YfvTL5rprrrxi1fsbF8vLy0xMTIy6jKHZSP1upF5h4/Rbd1bNzMycyMxGt211fDhXdFnX9V4iM2eBWYBGo5Gr/aCa5kOVZunvveY8951stXHy2eKP0P1Ao3JtpF5hY/Q77Kyq41UuS8D2tuVtwFM17LerfvNOzqFLWg9GkVV1BPo88I7Wq11uBM5l5g9r2G9XnfdqnQ9dSj9ClzQeRpFVVV62+Bng68AfRMRSRNwREXdFxF2tIUeBs8Ai8K/Ae2qvssOFC2Kl35K0Hgw7q/rOoWfm/j7bE/jT2iqqqPMCMcwlrUfDzKqxfaeoJOn5DHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVolKgR8SuiDgTEYsRcajL9ldHxIMR8WhEPBYRt9ZfqiSpl76BHhGbgMPALcBOYH9E7OwY9jfAkcy8FtgH/FPdhUqSeqtyhH49sJiZZzPzOWAO2NMxJoGXtE5fATxVX4mSpCoiM3sPiNgL7MrMO1vLtwE3ZObBtjGvAv4TeBlwGXBzZp7osq8DwAGAycnJ6+bm5tbcwPLyMhMTE2vez7iw33JtpF7BfldrZmbmRGY2um3bXOHvo8u6znuB/cDHM/O+iHgj8KmIuDozf/u8P8qcBWYBGo1GTk9PVzj73hYWFqhjP+PCfsu1kXoF+x2EKlMuS8D2tuVtXDylcgdwBCAzvw68CNhaR4GSpGqqBPpxYEdEXBURW2g+6TnfMeZ7wE0AEfF6moH+4zoLlST11jfQM/M8cBB4AHiC5qtZTkXEvRGxuzXsvcC7IuKbwGeA27Pf5LwkqVZV5tDJzKPA0Y5197SdPg28qd7SJEmXwneKSlIhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEJUCvSI2BURZyJiMSIOrTDmbRFxOiJORcSn6y1TktTP5n4DImITcBj4Y2AJOB4R85l5um3MDuCvgTdl5jMR8cpBFSxJ6q7KEfr1wGJmns3M54A5YE/HmHcBhzPzGYDMfLreMiVJ/URm9h4QsRfYlZl3tpZvA27IzINtY74AfAt4E7AJeH9m/keXfR0ADgBMTk5eNzc3t+YGlpeXmZiYWPN+xoX9lmsj9Qr2u1ozMzMnMrPRbVvfKRcguqzrvBfYDOwApoFtwFcj4urM/Pnz/ihzFpgFaDQaOT09XeHse1tYWKCO/YwL+y3XRuoV7HcQqky5LAHb25a3AU91GfPFzPxNZn4HOEMz4CVJQ1Il0I8DOyLiqojYAuwD5jvGfAGYAYiIrcDrgLN1FipJ6q1voGfmeeAg8ADwBHAkM09FxL0Rsbs17AHgpxFxGngQ+MvM/OmgipYkXazKHDqZeRQ42rHunrbTCdzd+pEkjYDvFJWkQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKkSlQI+IXRFxJiIWI+JQj3F7IyIjolFfiZKkKvoGekRsAg4DtwA7gf0RsbPLuMuBPwcerrtISVJ/VY7QrwcWM/NsZj4HzAF7uoz7APAh4Fc11idJqmhzhTFXAt9vW14CbmgfEBHXAtsz8/6I+IuVdhQRB4ADAJOTkywsLFxywZ2Wl5dr2c+4sN9ybaRewX4HoUqgR5d1+buNES8APgzc3m9HmTkLzAI0Go2cnp6uVGQvCwsL1LGfcWG/5dpIvYL9DkKVKZclYHvb8jbgqbbly4GrgYWIeBK4EZj3iVFJGq4qgX4c2BERV0XEFmAfMH9hY2aey8ytmTmVmVPAMWB3Zj4ykIolSV31DfTMPA8cBB4AngCOZOapiLg3InYPukBJUjVV5tDJzKPA0Y5196wwdnrtZUmSLpXvFJWkQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFqBToEbErIs5ExGJEHOqy/e6IOB0Rj0XElyPiNfWXKknqpW+gR8Qm4DBwC7AT2B8ROzuGPQo0MvMPgc8DH6q7UElSb1WO0K8HFjPzbGY+B8wBe9oHZOaDmfmL1uIxYFu9ZUqS+onM7D0gYi+wKzPvbC3fBtyQmQdXGP+PwP9m5t922XYAOAAwOTl53dzc3BrLh+XlZSYmJta8n3Fhv+XaSL2C/a7WzMzMicxsdNu2ucLfR5d1Xe8FIuLtQAN4c7ftmTkLzAI0Go2cnp6ucPa9LSwsUMd+xoX9lmsj9Qr2OwhVAn0J2N62vA14qnNQRNwMvA94c2b+up7yJElVVZlDPw7siIirImILsA+Ybx8QEdcCHwV2Z+bT9ZcpSeqnb6Bn5nngIPAA8ARwJDNPRcS9EbG7NezvgQngcxHxjYiYX2F3kqQBqTLlQmYeBY52rLun7fTNNdclSbpEvlNUkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhRjbQJ869KWey5K0HgwzqyoFekTsiogzEbEYEYe6bH9hRHy2tf3hiJiqu9B2Fy6QlX5L0now7KzqG+gRsQk4DNwC7AT2R8TOjmF3AM9k5u8DHwb+ru5CL+i8IE7+4FzP7ZI0CqPIqipH6NcDi5l5NjOfA+aAPR1j9gCfaJ3+PHBTRER9Zf6/Jz/4ljVtl6RhGEVWRWb2HhCxF9iVmXe2lm8DbsjMg21jHm+NWWotf7s15icd+zoAHACYnJy8bm5ubtWFX7i3m3wx/OiXzXXXXHnFqvc3LpaXl5mYmBh1GUOzkfrdSL3Cxum37qyamZk5kZmNbts2V/j7bkfanfcCVcaQmbPALECj0cjp6ekKZ3+x5kOVZunvveY8951stXHy2eKP0BcWFljt5TaONlK/G6lX2Bj9Djurqky5LAHb25a3AU+tNCYiNgNXAD+ro8BO/eadnEOXtB6MIquqBPpxYEdEXBURW4B9wHzHmHngna3Te4GvZL+5nFXqvFfrfOhS+hG6pPEwiqzqG+iZeR44CDwAPAEcycxTEXFvROxuDfs34OURsQjcDVz00sY6XbggVvotSevBsLOqyhw6mXkUONqx7p62078C3lpvab11XiCGuaT1aJhZNbbvFJUkPZ+BLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgrR98O5BnbGET8GvlvDrrYCP+k7qhz2W66N1CvY72q9JjNf0W3DyAK9LhHxyEqfPFYi+y3XRuoV7HcQnHKRpEIY6JJUiBICfXbUBQyZ/ZZrI/UK9lu7sZ9DlyQ1lXCELknCQJekYoxNoEfErog4ExGLEXHRF2hExAsj4rOt7Q9HxNTwq6xHhV7vjojTEfFYRHw5Il4zijrr0q/ftnF7IyIjYqxf6lal34h4W+s6PhURnx52jXWqcHt+dUQ8GBGPtm7Tt46izjpExMci4umIeHyF7RERH2ldFo9FxBtqLSAz1/0PsAn4NvBaYAvwTWBnx5j3AP/SOr0P+Oyo6x5grzPA77VOv3tce63ab2vc5cBDwDGgMeq6B3z97gAeBV7WWn7lqOsecL+zwLtbp3cCT4667jX0+0fAG4DHV9h+K/DvQAA3Ag/Xef7jcoR+PbCYmWcz8zlgDtjTMWYP8InW6c8DN0VEDLHGuvTtNTMfzMxftBaP0fzi7nFV5boF+ADwIeBXwyxuAKr0+y7gcGY+A5CZTw+5xjpV6TeBl7ROX8HFX0I/NjLzIeBnPYbsAT6ZTceAl0bEq+o6/3EJ9CuB77ctL7XWdR2Tze9BPQe8fCjV1atKr+3uoHmPP6769hsR1wLbM/P+YRY2IFWu39cBr4uIr0XEsYjYNbTq6lel3/cDb4+IJZpfdflnwyltJC71//uSVPpO0XWg25F25+stq4wZB5X7iIi3Aw3gzQOtaLB69hsRLwA+DNw+rIIGrMr1u5nmtMs0zUdfX42IqzPz5wOubRCq9Lsf+Hhm3hcRbwQ+1er3t4Mvb+gGmlPjcoS+BGxvW97GxQ/LfjcmIjbTfOjW66HPelWlVyLiZuB9wO7M/PWQahuEfv1eDlwNLETEkzTnHefH+InRqrflL2bmbzLzO8AZmgE/jqr0ewdwBCAzvw68iOYHWZWo0v/3ao1LoB8HdkTEVRGxheaTnvMdY+aBd7ZO7wW+kq1nIcZM315bUxAfpRnm4zy/Cn36zcxzmbk1M6cyc4rmcwa7M/OR0ZS7ZlVuy1+g+cQ3EbGV5hTM2aFWWZ8q/X4PuAkgIl5PM9B/PNQqh2ceeEfr1S43Aucy84e17X3UzwpfwrPHtwLfovmM+fta6+6l+c8NzRvB54BF4H+A14665gH2+l/Aj4BvtH7mR13zIPvtGLvAGL/KpeL1G8A/AKeBk8C+Udc84H53Al+j+QqYbwB/Muqa19DrZ4AfAr+heTR+B3AXcFfbdXu4dVmcrPu27Fv/JakQ4zLlIknqw0CXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5Jhfg/HSi4bYDA/YcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot y_pred against y_test to see what we're getting makes more or less sense\n",
    "plt.scatter(y_test, y_pred, marker='x')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Using already existing model: sagemaker-xgboost-210126-2305-012-3da3856a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb_best.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "# We need to tell the endpoint what format the data we are sending is in\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "xgb_predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into smaller chunks\n",
    "\n",
    "def predict_chunks(data, model, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, model.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.squeeze(np.round(predict_chunks(X_test.values, xgb_predictor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = xgb_predictor.predict(X_test.values).decode('utf-8')\n",
    "test_preds = np.fromstring(test_preds, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.array([1 if x >=0.5 else 0 for x in test_preds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "\n",
    "This section defines the functions that calculate the metrics used to evaluate the binary classifier on test data and compare its performance to the performance of the benchmark model.\n",
    "\n",
    "See: https://sinyi-chou.github.io/python-sklearn-precision-recall/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to evaluate the endpoint on test data\n",
    "# returns a variety of model metrics\n",
    "def evaluate(test_preds, test_labels, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction result and ground truth.  \n",
    "    Return binary classification metrics.\n",
    "    :param test_preds: Class prediction from the binary classifier\n",
    "    :param test_labels: Class labels for test data: ground truth\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    roc_auc = roc_auc_score(test_labels, test_preds)\n",
    "    auc_pr = average_precision_score(test_labels, test_preds)\n",
    "    \n",
    "    # print metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actuals'], colnames=['predictions']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print(\"{:<11} {:.3f}\".format('ROC AUC Score:', roc_auc))\n",
    "        print(\"{:<11} {:.3f}\".format('PR AUC Score:', auc_pr))\n",
    "        print()\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, \n",
    "            'Precision': precision, 'Recall': recall, 'Accuracy': accuracy, 'PR AUC Score': auc_pr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's evaluate our benchmark model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_benchmark = predictor_benchmark.predict(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results of the (naive) benchmark model: \n",
      "\n",
      "predictions     0     1\n",
      "actuals                \n",
      "0.0          2025  2801\n",
      "1.0          3461  5024\n",
      "\n",
      "Recall:     0.592\n",
      "Precision:  0.642\n",
      "Accuracy:   0.530\n",
      "ROC AUC Score: 0.506\n",
      "PR AUC Score: 0.640\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TP': 5024,\n",
       " 'FP': 2801,\n",
       " 'FN': 3461,\n",
       " 'TN': 2025,\n",
       " 'Precision': 0.6420447284345048,\n",
       " 'Recall': 0.5921037124337065,\n",
       " 'Accuracy': 0.5295620163774322,\n",
       " 'PR AUC Score': 0.6401675848715698}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Evaluation results of the (naive) benchmark model: \")\n",
    "print()\n",
    "evaluate(preds_benchmark, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions     0     1\n",
      "actuals                \n",
      "0.0          3266  1560\n",
      "1.0           673  7812\n",
      "\n",
      "Recall:     0.921\n",
      "Precision:  0.834\n",
      "Accuracy:   0.832\n",
      "ROC AUC Score: 0.799\n",
      "PR AUC Score: 0.818\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TP': 7812,\n",
       " 'FP': 1560,\n",
       " 'FN': 673,\n",
       " 'TN': 3266,\n",
       " 'Precision': 0.8335467349551856,\n",
       " 'Recall': 0.9206835592221567,\n",
       " 'Accuracy': 0.8322440087145969,\n",
       " 'PR AUC Score': 0.8179924621930712}"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate against what has been obtained from the deployed endpoint\n",
    "evaluate(test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13291\n",
      "Number of positive examples in validation dataset:  8519.0\n"
     ]
    }
   ],
   "source": [
    "# read validation data\n",
    "val_data = pd.read_csv(os.path.join(data_dir, 'validation.csv'), header=None)\n",
    "\n",
    "# the first column is ground truth\n",
    "y_val = val_data.values[:,0]\n",
    "print(len(val_data))\n",
    "print(\"Number of positive examples in validation dataset: \", sum(y_val))\n",
    "\n",
    "# validation features\n",
    "X_val = pd.DataFrame(val_data.values[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try evaluation deployed predictor on the validation set\n",
    "val_preds = np.squeeze(np.round(predict_chunks(X_val.values[:,1:], xgb_predictor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions   0.0   1.0\n",
      "actuals                \n",
      "0.0          3319  1453\n",
      "1.0          2242  6277\n",
      "\n",
      "Recall:     0.737\n",
      "Precision:  0.812\n",
      "Accuracy:   0.722\n",
      "ROC AUC Score: 0.716\n",
      "PR AUC Score: 0.767\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TP': 6277,\n",
       " 'FP': 1453,\n",
       " 'FN': 2242,\n",
       " 'TN': 3319,\n",
       " 'Precision': 0.8120310478654592,\n",
       " 'Recall': 0.7368235708416481,\n",
       " 'Accuracy': 0.7219923256338876,\n",
       " 'PR AUC Score': 0.7670091930285545}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(val_preds, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the data\n",
    "# !rm $data_dir/*\n",
    "\n",
    "# delete the directory itself\n",
    "# !rmdir $data_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
